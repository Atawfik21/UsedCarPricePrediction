{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# FET445 Project - Model Training\n",
                "**Student ID:** 22040301142\n",
                "**Group:** DevGrup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import time\n",
                "import joblib # Import joblib for saving models\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.metrics import mean_absolute_error, r2_score\n",
                "from sklearn.pipeline import Pipeline # We will use Pipelines\n",
                "\n",
                "# --- [1] Import Your Algorithms (Standard sklearn/CPU versions) ---\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from xgboost import XGBRegressor # This will use the CPU\n",
                "from sklearn.feature_selection import SelectKBest, f_regression # Import Feature Selector\n",
                "\n",
                "print(\"--- \u23f3 Loading Clean & Sampled Data (cars_cleaned_sampled.csv)... ---\")\n",
                "start_time = time.time()\n",
                "try:\n",
                "    df = pd.read_csv('cars_cleaned_sampled.csv')\n",
                "    print(f\"--- \ud83d\udfe2 Load successful! Rows: {len(df)} ---\")\n",
                "except FileNotFoundError:\n",
                "    print(\"--- \ud83d\udd34 ERROR: 'cars_cleaned_sampled.csv' not found. ---\")\n",
                "    print(\"--- Make sure the clean file is in the same folder as this script ---\")\n",
                "    exit()\n",
                "\n",
                "# --- Step 1: Pre-flight Clean (Drop 'mpg') ---\n",
                "if 'mpg' in df.columns:\n",
                "    df = df.drop('mpg', axis=1)\n",
                "    print(\"--- \u2139\ufe0f 'mpg' column dropped to simplify preprocessing. ---\")\n",
                "\n",
                "# --- Step 2: Define Features (X) and Target (y) ---\n",
                "y = df['price']\n",
                "X = df.drop('price', axis=1)\n",
                "print(f\"--- \u2139\ufe0f Target variable 'price' isolated. ---\")\n",
                "\n",
                "# --- Step 3: Define Column Types ---\n",
                "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
                "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
                "print(f\"--- \u2139\ufe0f Identified {len(numerical_features)} numerical features and {len(categorical_features)} categorical features. ---\")\n",
                "\n",
                "# --- Step 4: Create the Preprocessing Transformer ---\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', StandardScaler(), numerical_features),\n",
                "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
                "    ],\n",
                "    remainder='passthrough' \n",
                ")\n",
                "\n",
                "# --- Step 5: Split the Data (Train/Test Split) ---\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "print(f\"--- \ud83d\udfe2 Data split complete. Training on {len(X_train)} rows... ---\")\n",
                "\n",
                "# ==============================================================================\n",
                "# [!!!] AHMED'S 4 MODELS (CPU VERSION) [!!!]\n",
                "# (This will take a long time to run)\n",
                "# ==============================================================================\n",
                "all_results = {}\n",
                "all_pipelines = {} # To store the trained pipelines\n",
                "\n",
                "# --- [Model 1: Linear Regression (Baseline)] ---\n",
                "print(\"\\n--- \ud83d\ude80 [Model 1] Training Linear Regression... ---\")\n",
                "model_1_name = \"Linear Regression (Baseline)\"\n",
                "pipeline_lr = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                              ('model', LinearRegression())])\n",
                "pipeline_lr.fit(X_train, y_train)\n",
                "y_pred_1 = pipeline_lr.predict(X_test)\n",
                "all_results[model_1_name] = (r2_score(y_test, y_pred_1), mean_absolute_error(y_test, y_pred_1))\n",
                "all_pipelines[model_1_name] = pipeline_lr # Save pipeline\n",
                "print(f\"--- \ud83d\udfe2 {model_1_name} Trained. ---\")\n",
                "\n",
                "\n",
                "# --- [Model 2: Random Forest (Baseline)] ---\n",
                "print(\"\\n--- \ud83d\ude80 [Model 2] Training Random Forest (Baseline, n=100)... (This will take time) ---\")\n",
                "model_2_name = \"Random Forest (Baseline, n=100)\"\n",
                "pipeline_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                               # (n_jobs=-1 uses all available CPU cores)\n",
                "                               ('model', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))])\n",
                "pipeline_rf.fit(X_train, y_train)\n",
                "y_pred_2 = pipeline_rf.predict(X_test)\n",
                "all_results[model_2_name] = (r2_score(y_test, y_pred_2), mean_absolute_error(y_test, y_pred_2))\n",
                "all_pipelines[model_2_name] = pipeline_rf # Save pipeline\n",
                "print(f\"--- \ud83d\udfe2 {model_2_name} Trained. ---\")\n",
                "\n",
                "\n",
                "# --- [Model 3: Random Forest (with Feature Selection)] ---\n",
                "print(\"\\n--- \ud83d\ude80 [Model 3] Training Random Forest (on TOP 500 features)... ---\")\n",
                "model_3_name = \"RF (Top 500 Features)\"\n",
                "pipeline_rf_kbest = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                                    ('selector', SelectKBest(f_regression, k=500)), \n",
                "                                    ('model', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))])\n",
                "pipeline_rf_kbest.fit(X_train, y_train)\n",
                "y_pred_3 = pipeline_rf_kbest.predict(X_test)\n",
                "all_results[model_3_name] = (r2_score(y_test, y_pred_3), mean_absolute_error(y_test, y_pred_3))\n",
                "all_pipelines[model_3_name] = pipeline_rf_kbest # Save pipeline\n",
                "print(f\"--- \ud83d\udfe2 {model_3_name} Trained. ---\")\n",
                "\n",
                "\n",
                "# --- [Model 4: XGBoost (with Feature Selection)] ---\n",
                "print(\"\\n--- \ud83d\ude80 [Model 4] Training XGBoost (on TOP 500 features)... ---\")\n",
                "model_4_name = \"XGBoost (Top 500 Features)\"\n",
                "pipeline_xgb_kbest = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                                     ('selector', SelectKBest(f_regression, k=500)), \n",
                "                                     ('model', XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1))])\n",
                "pipeline_xgb_kbest.fit(X_train, y_train)\n",
                "y_pred_4 = pipeline_xgb_kbest.predict(X_test)\n",
                "all_results[model_4_name] = (r2_score(y_test, y_pred_4), mean_absolute_error(y_test, y_pred_4))\n",
                "all_pipelines[model_4_name] = pipeline_xgb_kbest # Save pipeline\n",
                "print(f\"--- \ud83d\udfe2 {model_4_name} Trained. ---\")\n",
                "\n",
                "\n",
                "# --- Final Results ---\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"--- \ud83d\udcca FINAL RESULTS (Ahmed's Models) ---\")\n",
                "print(\"=\"*50)\n",
                "for name, (r2, mae) in all_results.items():\n",
                "    print(f\"\\n--- \ud83d\udcc8 [RESULTS] {name} ---\")\n",
                "    print(f\"    R-squared (R2): {r2:.4f}\")\n",
                "    print(f\"    Mean Absolute Error (MAE): ${mae:.2f}\")\n",
                "\n",
                "end_time = time.time()\n",
                "print(f\"\\n--- \u2705 Total script time: {end_time - start_time:.2f} seconds ---\")\n",
                "\n",
                "\n",
                "# --- [NEW] Step 9: Save ALL 4 Models ---\n",
                "print(\"\\n--- \ud83d\udcbe Saving all 4 models... ---\")\n",
                "\n",
                "# Save Model 1\n",
                "model_1_pipeline = all_pipelines[\"Linear Regression (Baseline)\"]\n",
                "model_filename_1 = 'ahmed_model_1_LR.joblib'\n",
                "joblib.dump(model_1_pipeline, model_filename_1)\n",
                "print(f\"--- \ud83d\udfe2 Saved '{model_filename_1}' ---\")\n",
                "\n",
                "# Save Model 2\n",
                "model_2_pipeline = all_pipelines[\"Random Forest (Baseline, n=100)\"]\n",
                "model_filename_2 = 'ahmed_model_2_RF_Baseline.joblib'\n",
                "joblib.dump(model_2_pipeline, model_filename_2)\n",
                "print(f\"--- \ud83d\udfe2 Saved '{model_filename_2}' ---\")\n",
                "\n",
                "# Save Model 3\n",
                "model_3_pipeline = all_pipelines[\"RF (Top 500 Features)\"]\n",
                "model_filename_3 = 'ahmed_model_3_RF_Top500.joblib'\n",
                "joblib.dump(model_3_pipeline, model_filename_3)\n",
                "print(f\"--- \ud83d\udfe2 Saved '{model_filename_3}' ---\")\n",
                "\n",
                "# Save Model 4\n",
                "model_4_pipeline = all_pipelines[\"XGBoost (Top 500 Features)\"]\n",
                "model_filename_4 = 'ahmed_model_4_XGB_Top500.joblib'\n",
                "joblib.dump(model_4_pipeline, model_filename_4)\n",
                "print(f\"--- \ud83d\udfe2 Saved '{model_filename_4}' ---\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}